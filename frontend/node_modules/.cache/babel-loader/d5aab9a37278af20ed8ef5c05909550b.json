{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.isTokenType = exports.hasExtendingTokensTypesMapProperty = exports.hasExtendingTokensTypesProperty = exports.hasCategoriesProperty = exports.hasShortKeyProperty = exports.singleAssignCategoriesToksMap = exports.assignCategoriesMapProp = exports.assignCategoriesTokensProp = exports.assignTokenDefaultProps = exports.expandCategories = exports.augmentTokenTypes = exports.tokenIdxToClass = exports.tokenShortNameIdx = exports.tokenStructuredMatcherNoCategories = exports.tokenStructuredMatcher = void 0;\n\nvar isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\n\nvar compact_1 = __importDefault(require(\"lodash/compact\"));\n\nvar isArray_1 = __importDefault(require(\"lodash/isArray\"));\n\nvar flatten_1 = __importDefault(require(\"lodash/flatten\"));\n\nvar difference_1 = __importDefault(require(\"lodash/difference\"));\n\nvar map_1 = __importDefault(require(\"lodash/map\"));\n\nvar forEach_1 = __importDefault(require(\"lodash/forEach\"));\n\nvar has_1 = __importDefault(require(\"lodash/has\"));\n\nvar includes_1 = __importDefault(require(\"lodash/includes\"));\n\nvar clone_1 = __importDefault(require(\"lodash/clone\"));\n\nfunction tokenStructuredMatcher(tokInstance, tokConstructor) {\n  var instanceType = tokInstance.tokenTypeIdx;\n\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true;\n  } else {\n    return tokConstructor.isParent === true && tokConstructor.categoryMatchesMap[instanceType] === true;\n  }\n}\n\nexports.tokenStructuredMatcher = tokenStructuredMatcher; // Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\n\nfunction tokenStructuredMatcherNoCategories(token, tokType) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx;\n}\n\nexports.tokenStructuredMatcherNoCategories = tokenStructuredMatcherNoCategories;\nexports.tokenShortNameIdx = 1;\nexports.tokenIdxToClass = {};\n\nfunction augmentTokenTypes(tokenTypes) {\n  // collect the parent Token Types as well.\n  var tokenTypesAndParents = expandCategories(tokenTypes); // add required tokenType and categoryMatches properties\n\n  assignTokenDefaultProps(tokenTypesAndParents); // fill up the categoryMatches\n\n  assignCategoriesMapProp(tokenTypesAndParents);\n  assignCategoriesTokensProp(tokenTypesAndParents);\n  (0, forEach_1.default)(tokenTypesAndParents, function (tokType) {\n    tokType.isParent = tokType.categoryMatches.length > 0;\n  });\n}\n\nexports.augmentTokenTypes = augmentTokenTypes;\n\nfunction expandCategories(tokenTypes) {\n  var result = (0, clone_1.default)(tokenTypes);\n  var categories = tokenTypes;\n  var searching = true;\n\n  while (searching) {\n    categories = (0, compact_1.default)((0, flatten_1.default)((0, map_1.default)(categories, function (currTokType) {\n      return currTokType.CATEGORIES;\n    })));\n    var newCategories = (0, difference_1.default)(categories, result);\n    result = result.concat(newCategories);\n\n    if ((0, isEmpty_1.default)(newCategories)) {\n      searching = false;\n    } else {\n      categories = newCategories;\n    }\n  }\n\n  return result;\n}\n\nexports.expandCategories = expandCategories;\n\nfunction assignTokenDefaultProps(tokenTypes) {\n  (0, forEach_1.default)(tokenTypes, function (currTokType) {\n    if (!hasShortKeyProperty(currTokType)) {\n      exports.tokenIdxToClass[exports.tokenShortNameIdx] = currTokType;\n      currTokType.tokenTypeIdx = exports.tokenShortNameIdx++;\n    } // CATEGORIES? : TokenType | TokenType[]\n\n\n    if (hasCategoriesProperty(currTokType) && !(0, isArray_1.default)(currTokType.CATEGORIES) // &&\n    // !isUndefined(currTokType.CATEGORIES.PATTERN)\n    ) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES];\n    }\n\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = [];\n    }\n\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = [];\n    }\n\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {};\n    }\n  });\n}\n\nexports.assignTokenDefaultProps = assignTokenDefaultProps;\n\nfunction assignCategoriesTokensProp(tokenTypes) {\n  (0, forEach_1.default)(tokenTypes, function (currTokType) {\n    // avoid duplications\n    currTokType.categoryMatches = [];\n    (0, forEach_1.default)(currTokType.categoryMatchesMap, function (val, key) {\n      currTokType.categoryMatches.push(exports.tokenIdxToClass[key].tokenTypeIdx);\n    });\n  });\n}\n\nexports.assignCategoriesTokensProp = assignCategoriesTokensProp;\n\nfunction assignCategoriesMapProp(tokenTypes) {\n  (0, forEach_1.default)(tokenTypes, function (currTokType) {\n    singleAssignCategoriesToksMap([], currTokType);\n  });\n}\n\nexports.assignCategoriesMapProp = assignCategoriesMapProp;\n\nfunction singleAssignCategoriesToksMap(path, nextNode) {\n  (0, forEach_1.default)(path, function (pathNode) {\n    nextNode.categoryMatchesMap[pathNode.tokenTypeIdx] = true;\n  });\n  (0, forEach_1.default)(nextNode.CATEGORIES, function (nextCategory) {\n    var newPath = path.concat(nextNode); // avoids infinite loops due to cyclic categories.\n\n    if (!(0, includes_1.default)(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory);\n    }\n  });\n}\n\nexports.singleAssignCategoriesToksMap = singleAssignCategoriesToksMap;\n\nfunction hasShortKeyProperty(tokType) {\n  return (0, has_1.default)(tokType, \"tokenTypeIdx\");\n}\n\nexports.hasShortKeyProperty = hasShortKeyProperty;\n\nfunction hasCategoriesProperty(tokType) {\n  return (0, has_1.default)(tokType, \"CATEGORIES\");\n}\n\nexports.hasCategoriesProperty = hasCategoriesProperty;\n\nfunction hasExtendingTokensTypesProperty(tokType) {\n  return (0, has_1.default)(tokType, \"categoryMatches\");\n}\n\nexports.hasExtendingTokensTypesProperty = hasExtendingTokensTypesProperty;\n\nfunction hasExtendingTokensTypesMapProperty(tokType) {\n  return (0, has_1.default)(tokType, \"categoryMatchesMap\");\n}\n\nexports.hasExtendingTokensTypesMapProperty = hasExtendingTokensTypesMapProperty;\n\nfunction isTokenType(tokType) {\n  return (0, has_1.default)(tokType, \"tokenTypeIdx\");\n}\n\nexports.isTokenType = isTokenType;","map":{"version":3,"sources":["C:\\Users\\user\\Desktop\\Rue's Final Project\\frontend\\node_modules\\chevrotain\\src\\scan\\tokens.ts"],"names":[],"mappings":";;;;;;;;;;;;;AAAA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,IAAA,YAAA,GAAA,eAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;;AACA,IAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;;AACA,IAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,IAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;;AACA,IAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;;AACA,IAAA,OAAA,GAAA,eAAA,CAAA,OAAA,CAAA,cAAA,CAAA,CAAA;;AAGA,SAAgB,sBAAhB,CACE,WADF,EAEE,cAFF,EAE2B;AAEzB,MAAM,YAAY,GAAG,WAAW,CAAC,YAAjC;;AACA,MAAI,YAAY,KAAK,cAAc,CAAC,YAApC,EAAkD;AAChD,WAAO,IAAP;AACD,GAFD,MAEO;AACL,WACE,cAAc,CAAC,QAAf,KAA4B,IAA5B,IACA,cAAc,CAAC,kBAAf,CAAmC,YAAnC,MAAqD,IAFvD;AAID;AACF;;AAbD,OAAA,CAAA,sBAAA,GAAA,sBAAA,C,CAeA;AACA;;AACA,SAAgB,kCAAhB,CACE,KADF,EAEE,OAFF,EAEoB;AAElB,SAAO,KAAK,CAAC,YAAN,KAAuB,OAAO,CAAC,YAAtC;AACD;;AALD,OAAA,CAAA,kCAAA,GAAA,kCAAA;AAOW,OAAA,CAAA,iBAAA,GAAoB,CAApB;AACE,OAAA,CAAA,eAAA,GAAqD,EAArD;;AAEb,SAAgB,iBAAhB,CAAkC,UAAlC,EAAyD;AACvD;AACA,MAAM,oBAAoB,GAAG,gBAAgB,CAAC,UAAD,CAA7C,CAFuD,CAIvD;;AACA,EAAA,uBAAuB,CAAC,oBAAD,CAAvB,CALuD,CAOvD;;AACA,EAAA,uBAAuB,CAAC,oBAAD,CAAvB;AACA,EAAA,0BAA0B,CAAC,oBAAD,CAA1B;AAEA,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,oBAAR,EAA8B,UAAC,OAAD,EAAQ;AACpC,IAAA,OAAO,CAAC,QAAR,GAAmB,OAAO,CAAC,eAAR,CAAyB,MAAzB,GAAkC,CAArD;AACD,GAFD;AAGD;;AAdD,OAAA,CAAA,iBAAA,GAAA,iBAAA;;AAgBA,SAAgB,gBAAhB,CAAiC,UAAjC,EAAwD;AACtD,MAAI,MAAM,GAAG,CAAA,GAAA,OAAA,CAAA,OAAA,EAAM,UAAN,CAAb;AAEA,MAAI,UAAU,GAAG,UAAjB;AACA,MAAI,SAAS,GAAG,IAAhB;;AACA,SAAO,SAAP,EAAkB;AAChB,IAAA,UAAU,GAAG,CAAA,GAAA,SAAA,CAAA,OAAA,EACX,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,UAAJ,EAAgB,UAAC,WAAD,EAAY;AAAK,aAAA,WAAW,CAAX,UAAA;AAAsB,KAAvD,CAAR,CADW,CAAb;AAIA,QAAM,aAAa,GAAG,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,UAAX,EAAuB,MAAvB,CAAtB;AAEA,IAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,aAAd,CAAT;;AAEA,QAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,aAAR,CAAJ,EAA4B;AAC1B,MAAA,SAAS,GAAG,KAAZ;AACD,KAFD,MAEO;AACL,MAAA,UAAU,GAAG,aAAb;AACD;AACF;;AACD,SAAO,MAAP;AACD;;AArBD,OAAA,CAAA,gBAAA,GAAA,gBAAA;;AAuBA,SAAgB,uBAAhB,CAAwC,UAAxC,EAA+D;AAC7D,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,UAAR,EAAoB,UAAC,WAAD,EAAY;AAC9B,QAAI,CAAC,mBAAmB,CAAC,WAAD,CAAxB,EAAuC;AACrC,MAAA,OAAA,CAAA,eAAA,CAAgB,OAAA,CAAA,iBAAhB,IAAqC,WAArC;AACO,MAAA,WAAY,CAAC,YAAb,GAA4B,OAAA,CAAA,iBAAA,EAA5B;AACR,KAJ6B,CAM9B;;;AACA,QACE,qBAAqB,CAAC,WAAD,CAArB,IACA,CAAC,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,WAAW,CAAC,UAApB,CAFH,CAGE;AACA;AAJF,MAKE;AACA,MAAA,WAAW,CAAC,UAAZ,GAAyB,CAAC,WAAW,CAAC,UAAb,CAAzB;AACD;;AAED,QAAI,CAAC,qBAAqB,CAAC,WAAD,CAA1B,EAAyC;AACvC,MAAA,WAAW,CAAC,UAAZ,GAAyB,EAAzB;AACD;;AAED,QAAI,CAAC,+BAA+B,CAAC,WAAD,CAApC,EAAmD;AACjD,MAAA,WAAW,CAAC,eAAZ,GAA8B,EAA9B;AACD;;AAED,QAAI,CAAC,kCAAkC,CAAC,WAAD,CAAvC,EAAsD;AACpD,MAAA,WAAW,CAAC,kBAAZ,GAAiC,EAAjC;AACD;AACF,GA3BD;AA4BD;;AA7BD,OAAA,CAAA,uBAAA,GAAA,uBAAA;;AA+BA,SAAgB,0BAAhB,CAA2C,UAA3C,EAAkE;AAChE,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,UAAR,EAAoB,UAAC,WAAD,EAAY;AAC9B;AACA,IAAA,WAAW,CAAC,eAAZ,GAA8B,EAA9B;AACA,KAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,WAAW,CAAC,kBAApB,EAAyC,UAAC,GAAD,EAAM,GAAN,EAAS;AAChD,MAAA,WAAW,CAAC,eAAZ,CAA6B,IAA7B,CACE,OAAA,CAAA,eAAA,CAAgB,GAAhB,EAA0C,YAD5C;AAGD,KAJD;AAKD,GARD;AASD;;AAVD,OAAA,CAAA,0BAAA,GAAA,0BAAA;;AAYA,SAAgB,uBAAhB,CAAwC,UAAxC,EAA+D;AAC7D,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,UAAR,EAAoB,UAAC,WAAD,EAAY;AAC9B,IAAA,6BAA6B,CAAC,EAAD,EAAK,WAAL,CAA7B;AACD,GAFD;AAGD;;AAJD,OAAA,CAAA,uBAAA,GAAA,uBAAA;;AAMA,SAAgB,6BAAhB,CACE,IADF,EAEE,QAFF,EAEqB;AAEnB,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,IAAR,EAAc,UAAC,QAAD,EAAS;AACrB,IAAA,QAAQ,CAAC,kBAAT,CAA6B,QAAQ,CAAC,YAAtC,IAAuD,IAAvD;AACD,GAFD;AAIA,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,QAAQ,CAAC,UAAjB,EAA6B,UAAC,YAAD,EAAa;AACxC,QAAM,OAAO,GAAG,IAAI,CAAC,MAAL,CAAY,QAAZ,CAAhB,CADwC,CAExC;;AACA,QAAI,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,EAAkB,YAAlB,CAAL,EAAsC;AACpC,MAAA,6BAA6B,CAAC,OAAD,EAAU,YAAV,CAA7B;AACD;AACF,GAND;AAOD;;AAfD,OAAA,CAAA,6BAAA,GAAA,6BAAA;;AAiBA,SAAgB,mBAAhB,CAAoC,OAApC,EAAsD;AACpD,SAAO,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,cAAb,CAAP;AACD;;AAFD,OAAA,CAAA,mBAAA,GAAA,mBAAA;;AAIA,SAAgB,qBAAhB,CAAsC,OAAtC,EAAwD;AACtD,SAAO,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,YAAb,CAAP;AACD;;AAFD,OAAA,CAAA,qBAAA,GAAA,qBAAA;;AAIA,SAAgB,+BAAhB,CAAgD,OAAhD,EAAkE;AAChE,SAAO,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,iBAAb,CAAP;AACD;;AAFD,OAAA,CAAA,+BAAA,GAAA,+BAAA;;AAIA,SAAgB,kCAAhB,CACE,OADF,EACoB;AAElB,SAAO,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,oBAAb,CAAP;AACD;;AAJD,OAAA,CAAA,kCAAA,GAAA,kCAAA;;AAMA,SAAgB,WAAhB,CAA4B,OAA5B,EAA8C;AAC5C,SAAO,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,cAAb,CAAP;AACD;;AAFD,OAAA,CAAA,WAAA,GAAA,WAAA","sourcesContent":["import isEmpty from \"lodash/isEmpty\"\nimport compact from \"lodash/compact\"\nimport isArray from \"lodash/isArray\"\nimport flatten from \"lodash/flatten\"\nimport difference from \"lodash/difference\"\nimport map from \"lodash/map\"\nimport forEach from \"lodash/forEach\"\nimport has from \"lodash/has\"\nimport includes from \"lodash/includes\"\nimport clone from \"lodash/clone\"\nimport { IToken, TokenType } from \"@chevrotain/types\"\n\nexport function tokenStructuredMatcher(\n  tokInstance: IToken,\n  tokConstructor: TokenType\n) {\n  const instanceType = tokInstance.tokenTypeIdx\n  if (instanceType === tokConstructor.tokenTypeIdx) {\n    return true\n  } else {\n    return (\n      tokConstructor.isParent === true &&\n      tokConstructor.categoryMatchesMap![instanceType] === true\n    )\n  }\n}\n\n// Optimized tokenMatcher in case our grammar does not use token categories\n// Being so tiny it is much more likely to be in-lined and this avoid the function call overhead\nexport function tokenStructuredMatcherNoCategories(\n  token: IToken,\n  tokType: TokenType\n) {\n  return token.tokenTypeIdx === tokType.tokenTypeIdx\n}\n\nexport let tokenShortNameIdx = 1\nexport const tokenIdxToClass: { [tokenIdx: number]: TokenType } = {}\n\nexport function augmentTokenTypes(tokenTypes: TokenType[]): void {\n  // collect the parent Token Types as well.\n  const tokenTypesAndParents = expandCategories(tokenTypes)\n\n  // add required tokenType and categoryMatches properties\n  assignTokenDefaultProps(tokenTypesAndParents)\n\n  // fill up the categoryMatches\n  assignCategoriesMapProp(tokenTypesAndParents)\n  assignCategoriesTokensProp(tokenTypesAndParents)\n\n  forEach(tokenTypesAndParents, (tokType) => {\n    tokType.isParent = tokType.categoryMatches!.length > 0\n  })\n}\n\nexport function expandCategories(tokenTypes: TokenType[]): TokenType[] {\n  let result = clone(tokenTypes)\n\n  let categories = tokenTypes\n  let searching = true\n  while (searching) {\n    categories = compact(\n      flatten(map(categories, (currTokType) => currTokType.CATEGORIES))\n    )\n\n    const newCategories = difference(categories, result)\n\n    result = result.concat(newCategories)\n\n    if (isEmpty(newCategories)) {\n      searching = false\n    } else {\n      categories = newCategories\n    }\n  }\n  return result\n}\n\nexport function assignTokenDefaultProps(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    if (!hasShortKeyProperty(currTokType)) {\n      tokenIdxToClass[tokenShortNameIdx] = currTokType\n      ;(<any>currTokType).tokenTypeIdx = tokenShortNameIdx++\n    }\n\n    // CATEGORIES? : TokenType | TokenType[]\n    if (\n      hasCategoriesProperty(currTokType) &&\n      !isArray(currTokType.CATEGORIES)\n      // &&\n      // !isUndefined(currTokType.CATEGORIES.PATTERN)\n    ) {\n      currTokType.CATEGORIES = [currTokType.CATEGORIES as unknown as TokenType]\n    }\n\n    if (!hasCategoriesProperty(currTokType)) {\n      currTokType.CATEGORIES = []\n    }\n\n    if (!hasExtendingTokensTypesProperty(currTokType)) {\n      currTokType.categoryMatches = []\n    }\n\n    if (!hasExtendingTokensTypesMapProperty(currTokType)) {\n      currTokType.categoryMatchesMap = {}\n    }\n  })\n}\n\nexport function assignCategoriesTokensProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    // avoid duplications\n    currTokType.categoryMatches = []\n    forEach(currTokType.categoryMatchesMap!, (val, key) => {\n      currTokType.categoryMatches!.push(\n        tokenIdxToClass[key as unknown as number].tokenTypeIdx!\n      )\n    })\n  })\n}\n\nexport function assignCategoriesMapProp(tokenTypes: TokenType[]): void {\n  forEach(tokenTypes, (currTokType) => {\n    singleAssignCategoriesToksMap([], currTokType)\n  })\n}\n\nexport function singleAssignCategoriesToksMap(\n  path: TokenType[],\n  nextNode: TokenType\n): void {\n  forEach(path, (pathNode) => {\n    nextNode.categoryMatchesMap![pathNode.tokenTypeIdx!] = true\n  })\n\n  forEach(nextNode.CATEGORIES, (nextCategory) => {\n    const newPath = path.concat(nextNode)\n    // avoids infinite loops due to cyclic categories.\n    if (!includes(newPath, nextCategory)) {\n      singleAssignCategoriesToksMap(newPath, nextCategory)\n    }\n  })\n}\n\nexport function hasShortKeyProperty(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\")\n}\n\nexport function hasCategoriesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"CATEGORIES\")\n}\n\nexport function hasExtendingTokensTypesProperty(tokType: TokenType): boolean {\n  return has(tokType, \"categoryMatches\")\n}\n\nexport function hasExtendingTokensTypesMapProperty(\n  tokType: TokenType\n): boolean {\n  return has(tokType, \"categoryMatchesMap\")\n}\n\nexport function isTokenType(tokType: TokenType): boolean {\n  return has(tokType, \"tokenTypeIdx\")\n}\n"]},"metadata":{},"sourceType":"script"}